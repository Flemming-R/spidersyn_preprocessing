{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'db_id': 'str',\n",
       "  'SpiderQuestion': 'str',\n",
       "  'SpiderSynQuestion': 'str',\n",
       "  'query': 'str'}]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Pfad zur Datei\n",
    "# file_path = \"Spider-Syn-main/Spider-Syn/dev.json\"\n",
    "# file_path = \"Spider-Syn-main/preprocessed_dataset/tables.json\"\n",
    "# file_path = \"Spider-Syn-main/preprocessed_dataset/train_spider.json\"\n",
    "file_path = \"Spider-Syn-main/Spider-Syn/dev.json\"\n",
    "\n",
    "\n",
    "# JSON-Datei laden\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Struktur analysieren (rekursiv alle Schlüssel extrahieren)\n",
    "def extract_structure(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: extract_structure(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list) and obj:\n",
    "        return [extract_structure(obj[0])]\n",
    "    else:\n",
    "        return type(obj).__name__\n",
    "    \n",
    "\n",
    "# Struktur ausgeben\n",
    "structure = extract_structure(data)\n",
    "structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List, Dict, Optional\n",
    "# import numpy as np\n",
    "# import sqlite3\n",
    "\n",
    "# class QuestionAnswerMapping:\n",
    "#     \"\"\"\n",
    "#     Speichert die Zuordnung zwischen:\n",
    "#       - db_id: Identifikation der Datenbank\n",
    "#       - spider_question: Die originale Frage aus dem Spider-Datenset\n",
    "#       - spider_syn_question: Die synthetisierte Version der Frage (SpiderSyn)\n",
    "#       - query: Das zugehörige SQL-Query (aus dem Datenset)\n",
    "#       - generated_query: Ein von der Text-to-SQL Komponente generierter Query\n",
    "#       - spider_syn_embedding: Ein Embedding-Vektor für die SpiderSyn-Frage\n",
    "#     \"\"\"\n",
    "#     def __init__(self, \n",
    "#                  db_id: str, \n",
    "#                  spider_question: str, \n",
    "#                  spider_syn_question: str, \n",
    "#                  query: str, \n",
    "#                  generated_query: Optional[str] = None,\n",
    "#                  spider_syn_embedding: Optional[np.ndarray] = None):\n",
    "#         self.db_id = db_id\n",
    "#         self.spider_question = spider_question\n",
    "#         self.spider_syn_question = spider_syn_question\n",
    "#         self.query = query\n",
    "#         self.generated_query = generated_query\n",
    "#         self.spider_syn_embedding = spider_syn_embedding\n",
    "\n",
    "# class TableMapping:\n",
    "#     \"\"\"\n",
    "#     Speichert die Zuordnung zwischen dem verarbeiteten Tabellennamen und dem Originalnamen.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, table_name: str, original_table_name: str):\n",
    "#         self.table_name = table_name\n",
    "#         self.original_table_name = original_table_name\n",
    "\n",
    "# class ColumnMapping:\n",
    "#     \"\"\"\n",
    "#     Speichert die Zuordnung zwischen dem verarbeiteten Spaltennamen und dem Originalnamen.\n",
    "#     Zusätzlich wird festgehalten, zu welcher Tabelle die Spalte gehört.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, table_name: str, column_name: str, original_column_name: str):\n",
    "#         self.table_name = table_name\n",
    "#         self.column_name = column_name\n",
    "#         self.original_column_name = original_column_name\n",
    "\n",
    "\n",
    "# class MappingDB:\n",
    "#     \"\"\"\n",
    "#     Speichert für eine bestimmte Datenbank (über db_id) die\n",
    "#     Mapping-Informationen der Tabellen und Spalten, sowie zugehörige Embeddings.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, \n",
    "#                  db_id: str, \n",
    "#                  table_mappings: List[TableMapping], \n",
    "#                  column_mappings: List[ColumnMapping]):\n",
    "#         self.db_id = db_id\n",
    "#         self.table_mappings = table_mappings\n",
    "#         self.column_mappings = column_mappings\n",
    "#         # Hier werden Embeddings als Dictionary abgelegt:\n",
    "#         # key: table_name bzw. column_name, value: np.ndarray (Embedding-Vektor)\n",
    "#         self.table_embeddings: Dict[str, np.ndarray] = {}\n",
    "#         self.column_embeddings: Dict[str, np.ndarray] = {}\n",
    "\n",
    "#     def add_table_embedding(self, table_name: str, embedding: np.ndarray):\n",
    "#         self.table_embeddings[table_name] = embedding\n",
    "\n",
    "#     def add_column_embedding(self, column_name: str, embedding: np.ndarray):\n",
    "#         self.column_embeddings[column_name] = embedding\n",
    "\n",
    "# class SpiderDatabase:\n",
    "#     \"\"\"\n",
    "#     Schnittstelle zu einer gefüllten SQLite-Datenbank,\n",
    "#     die die tatsächlichen Daten aus dem Spider-Datenset enthält.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, db_path: str):\n",
    "#         self.db_path = db_path\n",
    "#         self.connection = sqlite3.connect(db_path)\n",
    "    \n",
    "#     def query(self, sql_query: str):\n",
    "#         cursor = self.connection.cursor()\n",
    "#         cursor.execute(sql_query)\n",
    "#         return cursor.fetchall()\n",
    "\n",
    "#     def close(self):\n",
    "#         self.connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import numpy as np\n",
    "# from typing import List, Dict, Optional\n",
    "\n",
    "# # Annahme: Die Klassen wurden bereits definiert:\n",
    "# # QuestionAnswerMapping, TableMapping, ColumnMapping, MappingDB\n",
    "\n",
    "# # Datei-Pfad zum JSON-Datensatz\n",
    "# # file_path_dev = \"Spider-Syn-main/preprocessed_dataset/dev.json\"\n",
    "# file_path_qa = \"Spider-Syn-main/Spider-Syn/dev.json\"\n",
    "\n",
    "\n",
    "# # Lade die JSON-Daten\n",
    "# with open(file_path_qa, \"r\", encoding=\"utf-8\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# # Listen und Dictionaries zur Speicherung der erstellten Objekte\n",
    "# question_answer_mappings: List[QuestionAnswerMapping] = []\n",
    "# mapping_dbs: Dict[str, MappingDB] = {}\n",
    "\n",
    "# for item in data:\n",
    "#     # Extrahiere die Basisinformationen aus dem JSON-Eintrag\n",
    "#     db_id = item.get(\"db_id\", \"\")\n",
    "#     spider_question = item.get(\"SpiderQuestion\", \"\")\n",
    "#     # Hier nehmen wir an, dass auch die synthetisierte Frage im Feld \"question\" liegt.\n",
    "#     # Falls es einen separaten Key gäbe, müsste hier angepasst werden.\n",
    "#     spider_syn_question = item.get(\"SpiderSynQuestion\", \"\")\n",
    "#     query = item.get(\"query\", \"\")\n",
    "#     # Initiales Embedding auf None setzen – kann später befüllt werden\n",
    "#     spider_syn_embedding = None\n",
    "\n",
    "#     # Erstelle ein QuestionAnswerMapping-Objekt\n",
    "#     qam = QuestionAnswerMapping(\n",
    "#         db_id=db_id,\n",
    "#         spider_question=spider_question,\n",
    "#         spider_syn_question=spider_syn_question,\n",
    "#         query=query,\n",
    "#         spider_syn_embedding=spider_syn_embedding\n",
    "#     )\n",
    "#     question_answer_mappings.append(qam)\n",
    "\n",
    "# print(f\"Es wurden {len(question_answer_mappings)} QuestionAnswerMapping-Objekte erstellt.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.flemmings_classes import QuestionAnswerMapping, TableMapping, ColumnMapping, MappingDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1034 QuestionAnswerMapping objects.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import List\n",
    "\n",
    "def load_dev_mappings(file_path_qa: str) -> List[QuestionAnswerMapping]:\n",
    "    \"\"\"\n",
    "    Load the dev.json file and create a list of QuestionAnswerMapping objects.\n",
    "\n",
    "    The JSON file is expected to be a list of dictionaries with the following keys:\n",
    "        - 'db_id'\n",
    "        - 'SpiderQuestion'\n",
    "        - 'SpiderSynQuestion'\n",
    "        - 'query'\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the dev.json file.\n",
    "\n",
    "    Returns:\n",
    "        List[QuestionAnswerMapping]: A list of QuestionAnswerMapping objects.\n",
    "    \"\"\"\n",
    "    with open(file_path_qa, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    qa_mappings: List[QuestionAnswerMapping] = []\n",
    "    for item in data:\n",
    "        mapping = QuestionAnswerMapping(\n",
    "            db_id=item.get(\"db_id\", \"\"),\n",
    "            spider_question=item.get(\"SpiderQuestion\", \"\"),\n",
    "            spider_syn_question=item.get(\"SpiderSynQuestion\", \"\"),\n",
    "            query=item.get(\"query\", \"\"),\n",
    "            spider_syn_embedding=None  # Initial value set to None\n",
    "        )\n",
    "        qa_mappings.append(mapping)\n",
    "\n",
    "    return qa_mappings\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    file_path_qa = \"Spider-Syn-main/Spider-Syn/dev.json\"\n",
    "    question_answer_mappings = load_dev_mappings(file_path_qa)\n",
    "    print(f\"Loaded {len(question_answer_mappings)} QuestionAnswerMapping objects.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1034 QuestionAnswerMapping objects.\n",
      "Example QuestionAnswerMapping object:\n",
      "{\n",
      "  \"db_id\": \"concert_singer\",\n",
      "  \"spider_question\": \"How many singers do we have?\",\n",
      "  \"spider_syn_question\": \"How many vocalists do we have?\",\n",
      "  \"query\": \"SELECT count(*) FROM singer\",\n",
      "  \"generated_query\": null,\n",
      "  \"spider_syn_embedding\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import List\n",
    "\n",
    "# Assuming the class QuestionAnswerMapping is already defined\n",
    "# For example:\n",
    "# class QuestionAnswerMapping:\n",
    "#     def __init__(self, db_id, spider_question, spider_syn_question, query, spider_syn_embedding):\n",
    "#         self.db_id = db_id\n",
    "#         self.spider_question = spider_question\n",
    "#         self.spider_syn_question = spider_syn_question\n",
    "#         self.query = query\n",
    "#         self.spider_syn_embedding = spider_syn_embedding\n",
    "\n",
    "from src.flemmings_functions import load_dev_mappings, custom_encoder\n",
    "\n",
    "# def load_dev_mappings(file_path: str) -> List[QuestionAnswerMapping]:\n",
    "#     \"\"\"\n",
    "#     Load the dev.json file and create a list of QuestionAnswerMapping objects.\n",
    "\n",
    "#     The JSON file is expected to be a list of dictionaries with the following keys:\n",
    "#         - 'db_id'\n",
    "#         - 'SpiderQuestion'\n",
    "#         - 'SpiderSynQuestion'\n",
    "#         - 'query'\n",
    "\n",
    "#     Args:\n",
    "#         file_path (str): Path to the dev.json file.\n",
    "\n",
    "#     Returns:\n",
    "#         List[QuestionAnswerMapping]: A list of QuestionAnswerMapping objects.\n",
    "#     \"\"\"\n",
    "#     with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "#         data = json.load(file)\n",
    "\n",
    "#     qa_mappings: List[QuestionAnswerMapping] = []\n",
    "#     for item in data:\n",
    "#         mapping = QuestionAnswerMapping(\n",
    "#             db_id=item.get(\"db_id\", \"\"),\n",
    "#             spider_question=item.get(\"SpiderQuestion\", \"\"),\n",
    "#             spider_syn_question=item.get(\"SpiderSynQuestion\", \"\"),\n",
    "#             query=item.get(\"query\", \"\"),\n",
    "#             spider_syn_embedding=None  # Initial value set to None\n",
    "#         )\n",
    "#         qa_mappings.append(mapping)\n",
    "\n",
    "#     return qa_mappings\n",
    "\n",
    "\n",
    "# def custom_encoder(obj):\n",
    "#     \"\"\"\n",
    "#     Custom JSON encoder function for objects that are not JSON serializable by default.\n",
    "\n",
    "#     Args:\n",
    "#         obj: The object to encode.\n",
    "\n",
    "#     Returns:\n",
    "#         The object's __dict__ if available.\n",
    "\n",
    "#     Raises:\n",
    "#         TypeError: If the object cannot be serialized.\n",
    "#     \"\"\"\n",
    "#     if hasattr(obj, '__dict__'):\n",
    "#         return obj.__dict__\n",
    "#     raise TypeError(f\"Object of type {obj.__class__.__name__} is not JSON serializable\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"Spider-Syn-main/Spider-Syn/dev.json\"\n",
    "    question_answer_mappings = load_dev_mappings(file_path)\n",
    "    print(f\"Loaded {len(question_answer_mappings)} QuestionAnswerMapping objects.\")\n",
    "\n",
    "    # Choose one example object (here: the first one in the list)\n",
    "    example_mapping = question_answer_mappings[0]\n",
    "\n",
    "    # Serialize the example object to a JSON formatted string\n",
    "    json_str = json.dumps(example_mapping, default=custom_encoder, indent=2, ensure_ascii=False)\n",
    "    print(\"Example QuestionAnswerMapping object:\")\n",
    "    print(json_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erstellte MappingDB-Objekte: 166\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "\n",
    "# Wir nehmen an, dass die Klassen schon definiert sind:\n",
    "# TableMapping, ColumnMapping, MappingDB\n",
    "\n",
    "file_path_tables = \"Spider-Syn-main/preprocessed_dataset/tables.json\"\n",
    "\n",
    "with open(file_path_tables, \"r\", encoding=\"utf-8\") as f:\n",
    "    tables_data = json.load(f)\n",
    "\n",
    "mapping_dbs: Dict[str, MappingDB] = {}\n",
    "\n",
    "# Die Variable tables_data ist eine LISTE, in der jeder Eintrag das Schema einer DB beschreibt\n",
    "for db_schema in tables_data:\n",
    "    # 1) DB-spezifische Infos auslesen\n",
    "    db_id = db_schema[\"db_id\"]\n",
    "    table_names = db_schema[\"table_names\"]                 # [\"table1\", \"table2\", ...]\n",
    "    table_names_original = db_schema[\"table_names_original\"] # [\"Table1\", \"Table2\", ...] (oder ähnlich)\n",
    "    column_names = db_schema[\"column_names\"]               # [[table_idx, \"column_name\"], ...]\n",
    "    column_names_original = db_schema[\"column_names_original\"] # [[table_idx, \"column_name_orig\"], ...]\n",
    "\n",
    "    # 2) TableMapping-Objekte erstellen\n",
    "    table_mappings: List[TableMapping] = []\n",
    "    for tname, tname_orig in zip(table_names, table_names_original):\n",
    "        table_mappings.append(TableMapping(\n",
    "            table_name=tname,\n",
    "            original_table_name=tname_orig\n",
    "        ))\n",
    "\n",
    "    # 3) ColumnMapping-Objekte erstellen\n",
    "    column_mappings: List[ColumnMapping] = []\n",
    "    for (tbl_idx, col_name), (_, col_name_orig) in zip(column_names, column_names_original):\n",
    "        if tbl_idx == -1:\n",
    "            # -1 bedeutet \"Sternchen\" oder keine bestimmte Tabelle\n",
    "            # Wir können das Tabellennamen-Feld leer lassen oder \"*\"\n",
    "            table_name = \"\"\n",
    "        else:\n",
    "            # Ansonsten den Tabellenindex benutzen, um den zugehörigen Tabellennamen zu holen\n",
    "            # und sicherstellen, dass wir nicht out-of-bounds laufen\n",
    "            try:\n",
    "                table_name = table_names[tbl_idx]\n",
    "            except IndexError:\n",
    "                table_name = \"\"\n",
    "        \n",
    "        column_mappings.append(ColumnMapping(\n",
    "            table_name=table_name,\n",
    "            column_name=col_name,\n",
    "            original_column_name=col_name_orig\n",
    "        ))\n",
    "    \n",
    "    # 4) MappingDB-Objekt für diese Datenbank erstellen\n",
    "    mapping_dbs[db_id] = MappingDB(\n",
    "        db_id=db_id,\n",
    "        table_mappings=table_mappings,\n",
    "        column_mappings=column_mappings\n",
    "    )\n",
    "\n",
    "print(f\"Erstellte MappingDB-Objekte: {len(mapping_dbs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"db_id\": \"perpetrator\",\n",
      "  \"table_mappings\": [\n",
      "    {\n",
      "      \"table_name\": \"perpetrator\",\n",
      "      \"original_table_name\": \"perpetrator\"\n",
      "    },\n",
      "    {\n",
      "      \"table_name\": \"people\",\n",
      "      \"original_table_name\": \"people\"\n",
      "    }\n",
      "  ],\n",
      "  \"column_mappings\": [\n",
      "    {\n",
      "      \"table_name\": \"\",\n",
      "      \"column_name\": \"*\",\n",
      "      \"original_column_name\": \"*\"\n",
      "    },\n",
      "    {\n",
      "      \"table_name\": \"perpetrator\",\n",
      "      \"column_name\": \"perpetrator id\",\n",
      "      \"original_column_name\": \"Perpetrator_ID\"\n",
      "    },\n",
      "    {\n",
      "      \"table_name\": \"perpetrator\",\n",
      "      \"column_name\": \"people id\",\n",
      "      \"original_column_name\": \"People_ID\"\n",
      "    },\n",
      "    {\n",
      "      \"table_name\": \"perpetrator\",\n",
      "      \"column_name\": \"date\",\n",
      "      \"original_column_name\": \"Date\"\n",
      "    },\n",
      "    {\n",
      "      \"table_name\": \"perpetrator\",\n",
      "      \"column_name\": \"year\",\n",
      "      \"original_column_name\": \"Year\"\n",
      "    },\n",
      "    {\n",
      "      \"table_name\": \"perpetrator\",\n",
      "      \"column_name\": \"location\",\n",
      "      \"original_column_name\": \"Location\"\n",
      "    },\n",
      "    {\n",
      "      \"table_name\": \"perpetrator\",\n",
      "      \"column_name\": \"country\",\n",
      "      \"original_column_name\": \"Country\"\n",
      "    },\n",
      "    {\n",
      "      \"table_name\": \"perpetrator\",\n",
      "      \"column_name\": \"killed\",\n",
      "      \"original_column_name\": \"Killed\"\n",
      "    },\n",
      "    {\n",
      "      \"table_name\": \"perpetrator\",\n",
      "      \"column_name\": \"injured\",\n",
      "      \"original_column_name\": \"Injured\"\n",
      "    },\n",
      "    {\n",
      "      \"table_name\": \"people\",\n",
      "      \"column_name\": \"people id\",\n",
      "      \"original_column_name\": \"People_ID\"\n",
      "    },\n",
      "    {\n",
      "      \"table_name\": \"people\",\n",
      "      \"column_name\": \"name\",\n",
      "      \"original_column_name\": \"Name\"\n",
      "    },\n",
      "    {\n",
      "      \"table_name\": \"people\",\n",
      "      \"column_name\": \"height\",\n",
      "      \"original_column_name\": \"Height\"\n",
      "    },\n",
      "    {\n",
      "      \"table_name\": \"people\",\n",
      "      \"column_name\": \"weight\",\n",
      "      \"original_column_name\": \"Weight\"\n",
      "    },\n",
      "    {\n",
      "      \"table_name\": \"people\",\n",
      "      \"column_name\": \"home town\",\n",
      "      \"original_column_name\": \"Home Town\"\n",
      "    }\n",
      "  ],\n",
      "  \"table_embeddings\": {},\n",
      "  \"column_embeddings\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Wähle ein Beispielobjekt aus\n",
    "example_db = next(iter(mapping_dbs.values()))\n",
    "\n",
    "# Benutzerdefinierte Funktion für den JSON-Encoder\n",
    "def custom_encoder(obj):\n",
    "    if hasattr(obj, '__dict__'):\n",
    "        return obj.__dict__\n",
    "    # Bei Listen oder anderen iterierbaren Typen wird rekursiv serialisiert\n",
    "    raise TypeError(f\"Object of type {obj.__class__.__name__} is not JSON serializable\")\n",
    "\n",
    "# Serialisiere das Objekt unter Verwendung der custom_encoder-Funktion\n",
    "json_str = json.dumps(example_db, default=custom_encoder, indent=2, ensure_ascii=False)\n",
    "print(json_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es existieren folgende Tabellen:\n",
      "['perpetrator', 'college_2', 'flight_company', 'icfp_1', 'body_builder', 'storm_record', 'pilot_record', 'race_track', 'academic', 'department_store', 'music_4', 'insurance_fnol', 'cinema', 'decoration_competition', 'phone_market', 'store_product', 'assets_maintenance', 'student_assessment', 'dog_kennels', 'music_1', 'company_employee', 'farm', 'solvency_ii', 'city_record', 'swimming', 'flight_2', 'election', 'manufactory_1', 'debate', 'network_2', 'local_govt_in_alabama', 'climbing', 'e_learning', 'scientist_1', 'ship_1', 'entertainment_awards', 'allergy_1', 'imdb', 'products_for_hire', 'candidate_poll', 'chinook_1', 'flight_4', 'pets_1', 'dorm_1', 'journal_committee', 'flight_1', 'medicine_enzyme_interaction', 'local_govt_and_lot', 'station_weather', 'shop_membership', 'driving_school', 'concert_singer', 'music_2', 'sports_competition', 'railway', 'inn_1', 'museum_visit', 'browser_web', 'baseball_1', 'architecture', 'csu_1', 'tracking_orders', 'insurance_policies', 'gas_company', 'e_government', 'school_bus', 'machine_repair', 'theme_gallery', 'film_rank', 'party_people', 'hospital_1', 'customers_campaigns_ecommerce', 'gymnast', 'restaurants', 'mountain_photos', 'battle_death', 'cre_Doc_Control_Systems', 'tracking_share_transactions', 'apartment_rentals', 'student_transcripts_tracking', 'cre_Docs_and_Epenses', 'ship_mission', 'company_office', 'tracking_software_problems', 'products_gen_characteristics', 'coffee_shop', 'riding_club', 'customers_card_transactions', 'county_public_safety', 'performance_attendance', 'club_1', 'singer', 'culture_company', 'cre_Doc_Template_Mgt', 'musical', 'world_1', 'device', 'tracking_grants_for_research', 'employee_hire_evaluation', 'movie_1', 'network_1', 'poker_player', 'program_share', 'aircraft', 'restaurant_1', 'customers_and_invoices', 'insurance_and_eClaims', 'college_1', 'local_govt_mdm', 'book_2', 'hr_1', 'soccer_1', 'sakila_1', 'real_estate_properties', 'college_3', 'course_teach', 'roller_coaster', 'customer_deliveries', 'game_injury', 'school_finance', 'scholar', 'voter_1', 'match_season', 'small_bank_1', 'wta_1', 'yelp', 'student_1', 'manufacturer', 'store_1', 'train_station', 'document_management', 'formula_1', 'game_1', 'loan_1', 'bike_1', 'entrepreneur', 'orchestra', 'cre_Drama_Workshop_Groups', 'car_1', 'geo', 'behavior_monitoring', 'cre_Doc_Tracking_DB', 'university_basketball', 'soccer_2', 'activity_1', 'cre_Theme_park', 'twitter_1', 'election_representative', 'voter_2', 'wedding', 'news_report', 'wine_1', 'customers_and_addresses', 'protein_institute', 'school_player', 'phone_1', 'tvshow', 'wrestler', 'customer_complaints', 'department_management', 'customers_and_products_contacts', 'company_1', 'workshop_paper', 'epinions_1', 'party_host', 'product_catalog']\n",
      "\n",
      "\n",
      "Anzahl Tabellen insgesamt:\n",
      "166\n"
     ]
    }
   ],
   "source": [
    "print(f\"Es existieren folgende Tabellen:\\n{list(mapping_dbs.keys())}\\n\\n\")\n",
    "\n",
    "print(f\"Anzahl Tabellen insgesamt:\\n{len(list(mapping_dbs.keys()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== QuestionAnswerMapping ===\n",
      "DB ID: network_1\n",
      "Originalfrage (Spider): How many likes does Kyle have?\n",
      "Synthetisierte Frage (SpiderSyn): How many interests does Kyle have?\n",
      "Query: SELECT count(*) FROM Likes AS T1 JOIN Highschooler AS T2 ON T1.student_id  =  T2.id WHERE T2.name  =  \"Kyle\"\n",
      "Generated Query: None\n",
      "Embedding (SpiderSyn): None\n"
     ]
    }
   ],
   "source": [
    "# Beispiel: Erstes QuestionAnswerMapping-Objekt anzeigen\n",
    "first_qam = question_answer_mappings[912]\n",
    "\n",
    "print(\"=== QuestionAnswerMapping ===\")\n",
    "print(f\"DB ID: {first_qam.db_id}\")\n",
    "print(f\"Originalfrage (Spider): {first_qam.spider_question}\")\n",
    "print(f\"Synthetisierte Frage (SpiderSyn): {first_qam.spider_syn_question}\")\n",
    "print(f\"Query: {first_qam.query}\")\n",
    "print(f\"Generated Query: {first_qam.generated_query}\")\n",
    "print(f\"Embedding (SpiderSyn): {first_qam.spider_syn_embedding}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'db_id': 'concert_singer', 'spider_question': 'What is the average , minimum , and maximum age for all France singers ?', 'spider_syn_question': 'What is the average , minimum , and maximum age for all France singers ?', 'query': \"SELECT avg(age) ,  min(age) ,  max(age) FROM singer WHERE country  =  'France'\", 'generated_query': None, 'spider_syn_embedding': None}\n"
     ]
    }
   ],
   "source": [
    "print(vars(first_qam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MappingDB ===\n",
      "DB ID: music_1\n",
      "\n",
      "Tabellen-Mappings:\n",
      "- genre (Original: genre)\n",
      "- artist (Original: artist)\n",
      "- files (Original: files)\n",
      "- song (Original: song)\n",
      "\n",
      "Spalten-Mappings:\n",
      "- * (Original: *, Tabelle: )\n",
      "- genre name (Original: g_name, Tabelle: genre)\n",
      "- rating (Original: rating, Tabelle: genre)\n",
      "- most popular in (Original: most_popular_in, Tabelle: genre)\n",
      "- artist name (Original: artist_name, Tabelle: artist)\n",
      "- country (Original: country, Tabelle: artist)\n",
      "- gender (Original: gender, Tabelle: artist)\n",
      "- preferred genre (Original: preferred_genre, Tabelle: artist)\n",
      "- song id (Original: f_id, Tabelle: files)\n",
      "- artist name (Original: artist_name, Tabelle: files)\n",
      "- file size (Original: file_size, Tabelle: files)\n",
      "- duration (Original: duration, Tabelle: files)\n",
      "- formats (Original: formats, Tabelle: files)\n",
      "- song name (Original: song_name, Tabelle: song)\n",
      "- artist name (Original: artist_name, Tabelle: song)\n",
      "- country (Original: country, Tabelle: song)\n",
      "- song id (Original: f_id, Tabelle: song)\n",
      "- genre is (Original: genre_is, Tabelle: song)\n",
      "- rating (Original: rating, Tabelle: song)\n",
      "- languages (Original: languages, Tabelle: song)\n",
      "- releasedate (Original: releasedate, Tabelle: song)\n",
      "- resolution (Original: resolution, Tabelle: song)\n",
      "\n",
      "Table-Embeddings (nur Keys):\n",
      "[]\n",
      "\n",
      "Column-Embeddings (nur Keys):\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Hole das erste MappingDB-Objekt aus dem Dictionary\n",
    "first_db_id = list(mapping_dbs.keys())[19]\n",
    "first_mapping_db = mapping_dbs[first_db_id]\n",
    "\n",
    "print(\"=== MappingDB ===\")\n",
    "print(f\"DB ID: {first_mapping_db.db_id}\")\n",
    "\n",
    "print(\"\\nTabellen-Mappings:\")\n",
    "for table in first_mapping_db.table_mappings:\n",
    "    print(f\"- {table.table_name} (Original: {table.original_table_name})\")\n",
    "\n",
    "print(\"\\nSpalten-Mappings:\")\n",
    "for column in first_mapping_db.column_mappings:\n",
    "    print(f\"- {column.column_name} (Original: {column.original_column_name}, Tabelle: {column.table_name})\")\n",
    "\n",
    "print(\"\\nTable-Embeddings (nur Keys):\")\n",
    "print(list(first_mapping_db.table_embeddings.keys()))\n",
    "\n",
    "print(\"\\nColumn-Embeddings (nur Keys):\")\n",
    "print(list(first_mapping_db.column_embeddings.keys()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
